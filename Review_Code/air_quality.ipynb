{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e72173a-9560-40e2-ae71-679826d42faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 360, 'name': 'Air Quality', 'repository_url': 'https://archive.ics.uci.edu/dataset/360/air+quality', 'data_url': 'https://archive.ics.uci.edu/static/public/360/data.csv', 'abstract': 'Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. ', 'area': 'Computer Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate', 'Time-Series'], 'num_instances': 9358, 'num_features': 15, 'feature_types': ['Real'], 'demographics': [], 'target_col': None, 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2008, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C59K5F', 'creators': ['Saverio Vito'], 'intro_paper': {'title': 'On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario', 'authors': 'S. D. Vito, E. Massera, M. Piga, L. Martinotto, G. Francia', 'published_in': 'Sensors and Actuators B: Chemical', 'year': 2008, 'url': 'https://www.semanticscholar.org/paper/a90a54a39ff934772df57771a0012981f355949d', 'doi': '10.1016/j.snb.2007.09.060'}, 'additional_info': {'summary': 'The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\\r\\nThis dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '0 Date\\t(DD/MM/YYYY)\\r\\n1 Time\\t(HH.MM.SS)\\r\\n2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)\\r\\n3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)\\t\\r\\n4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\\r\\n5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)\\r\\n6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\\t\\r\\n7 True hourly averaged NOx concentration  in ppb (reference analyzer)\\r\\n8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \\r\\n9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\\t\\r\\n10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\\t\\r\\n11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\\r\\n12 Temperature in Â°C\\t\\r\\n13 Relative Humidity (%) \\t\\r\\n14 AH Absolute Humidity\\r\\n', 'citation': None}}\n",
      "             name     role         type demographic  \\\n",
      "0            Date  Feature         Date        None   \n",
      "1            Time  Feature  Categorical        None   \n",
      "2          CO(GT)  Feature      Integer        None   \n",
      "3     PT08.S1(CO)  Feature  Categorical        None   \n",
      "4        NMHC(GT)  Feature      Integer        None   \n",
      "5        C6H6(GT)  Feature   Continuous        None   \n",
      "6   PT08.S2(NMHC)  Feature  Categorical        None   \n",
      "7         NOx(GT)  Feature      Integer        None   \n",
      "8    PT08.S3(NOx)  Feature  Categorical        None   \n",
      "9         NO2(GT)  Feature      Integer        None   \n",
      "10   PT08.S4(NO2)  Feature  Categorical        None   \n",
      "11    PT08.S5(O3)  Feature  Categorical        None   \n",
      "12              T  Feature   Continuous        None   \n",
      "13             RH  Feature   Continuous        None   \n",
      "14             AH  Feature   Continuous        None   \n",
      "\n",
      "                                          description       units  \\\n",
      "0                                                None        None   \n",
      "1                                                None        None   \n",
      "2   True hourly averaged concentration CO in mg/m^...      mg/m^3   \n",
      "3   hourly averaged sensor response (nominally  CO...        None   \n",
      "4   True hourly averaged overall Non Metanic Hydro...  microg/m^3   \n",
      "5   True hourly averaged Benzene concentration  in...  microg/m^3   \n",
      "6   hourly averaged sensor response (nominally NMH...        None   \n",
      "7   True hourly averaged NOx concentration  in ppb...         ppb   \n",
      "8   hourly averaged sensor response (nominally NOx...        None   \n",
      "9   True hourly averaged NO2 concentration in micr...  microg/m^3   \n",
      "10  hourly averaged sensor response (nominally NO2...        None   \n",
      "11  hourly averaged sensor response (nominally O3 ...        None   \n",
      "12                                        Temperature          °C   \n",
      "13                                  Relative Humidity           %   \n",
      "14                                  Absolute Humidity        None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "air_quality = fetch_ucirepo(id=360) \n",
    "# metadata \n",
    "print(air_quality.metadata) \n",
    "# variable information \n",
    "print(air_quality.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9a19e4-8ea7-4016-b43b-b35b36001e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = air_quality.data.features['C6H6(GT)']\n",
    "X = air_quality.data.features.drop(columns=['C6H6(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7448c57-0871-47ea-b9c5-77612b2129e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Date has string data: ['3/10/2004' '3/11/2004' '3/12/2004' '3/13/2004' '3/14/2004']\n",
      "Column Time has string data: ['18:00:00' '19:00:00' '20:00:00' '21:00:00' '22:00:00']\n",
      "CO(GT)           float64\n",
      "PT08.S1(CO)        int64\n",
      "NMHC(GT)           int64\n",
      "PT08.S2(NMHC)      int64\n",
      "NOx(GT)            int64\n",
      "PT08.S3(NOx)       int64\n",
      "NO2(GT)            int64\n",
      "PT08.S4(NO2)       int64\n",
      "PT08.S5(O3)        int64\n",
      "T                float64\n",
      "RH               float64\n",
      "AH               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 문자열 데이터가 포함된 열 확인\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        print(f\"Column {column} has string data: {X[column].unique()[:5]}\")\n",
    "\n",
    "# 예를 들어 특정 열이 여전히 문자열을 포함하고 있다면, 제거하거나 변환해야 합니다.\n",
    "# 문자열 열을 드롭합니다.\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "\n",
    "# 모든 열이 수치형인지 다시 확인합니다.\n",
    "print(X.dtypes)\n",
    "\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 시계열 데이터로 변환하기 위해 시퀀스 생성\n",
    "time_steps = 10\n",
    "\n",
    "def create_sequences(X, y, time_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps), :])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y, time_steps)\n",
    "\n",
    "# 데이터셋을 훈련, 검증, 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a55b60-4080-4db7-9490-5e4756dcf783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# LSTM 모델 정의\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = RMSprop(learning_rate=0.001, clipnorm=1.0)  # Gradient clipping added\n",
    "    model.compile(optimizer=RMSprop(), loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# GRU 모델 정의\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = RMSprop(learning_rate=0.001, clipnorm=1.0)  # Gradient clipping added\n",
    "    model.compile(optimizer=RMSprop(), loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# SimpleRNN(tanh) 모델 정의\n",
    "def build_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = RMSprop(learning_rate=0.001, clipnorm=1.0)  # Gradient clipping added\n",
    "    model.compile(optimizer=RMSprop(), loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련\n",
    "lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "gru_model = build_gru_model((X_train.shape[1], X_train.shape[2]))\n",
    "rnn_model = build_rnn_model((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
    "gru_history = gru_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eda404-a41d-4639-98ef-6962fa52b9a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "y_pred_gru = gru_model.predict(X_test)\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "\n",
    "# MSE 계산\n",
    "lstm_mse = mean_squared_error(y_test, y_pred_lstm)\n",
    "gru_mse = mean_squared_error(y_test, y_pred_gru)\n",
    "rnn_mse = mean_squared_error(y_test, y_pred_rnn)\n",
    "\n",
    "# MAE 계산\n",
    "lstm_mae = mean_absolute_error(y_test, y_pred_lstm)\n",
    "gru_mae = mean_absolute_error(y_test, y_pred_gru)\n",
    "rnn_mae = mean_absolute_error(y_test, y_pred_rnn)\n",
    "\n",
    "# R^2 Score 계산\n",
    "lstm_r2 = r2_score(y_test, y_pred_lstm)\n",
    "gru_r2 = r2_score(y_test, y_pred_gru)\n",
    "rnn_r2 = r2_score(y_test, y_pred_rnn)\n",
    "\n",
    "print(f\"LSTM MSE: {lstm_mse}, MAE: {lstm_mae}, R^2: {lstm_r2}\")\n",
    "print(f\"GRU MSE: {gru_mse}, MAE: {gru_mae}, R^2: {gru_r2}\")\n",
    "print(f\"RNN MSE: {rnn_mse}, MAE: {rnn_mae}, R^2: {rnn_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff44647-9586-43e7-8bd9-d4f132e02524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 학습 및 검증 손실 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Epochs 기준 그래프\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(rnn_history.history['loss'], label='tanh train', color='blue')\n",
    "plt.plot(rnn_history.history['val_loss'], label='tanh valid', color='blue', linestyle='--')\n",
    "plt.plot(gru_history.history['loss'], label='GRU train', color='green')\n",
    "plt.plot(gru_history.history['val_loss'], label='GRU valid', color='green', linestyle='--')\n",
    "plt.plot(lstm_history.history['loss'], label='LSTM train', color='purple')\n",
    "plt.plot(lstm_history.history['val_loss'], label='LSTM valid', color='purple', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.title('Per epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 시간 기준 그래프\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(np.cumsum(rnn_history.history['loss']), label='tanh train', color='blue')\n",
    "plt.plot(np.cumsum(rnn_history.history['val_loss']), label='tanh valid', color='blue', linestyle='--')\n",
    "plt.plot(np.cumsum(gru_history.history['loss']), label='GRU train', color='green')\n",
    "plt.plot(np.cumsum(gru_history.history['val_loss']), label='GRU valid', color='green', linestyle='--')\n",
    "plt.plot(np.cumsum(lstm_history.history['loss']), label='LSTM train', color='purple')\n",
    "plt.plot(np.cumsum(lstm_history.history['val_loss']), label='LSTM valid', color='purple', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.title('Wall Clock Time (seconds)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cumulative Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 두 그래프를 합친 제목 추가\n",
    "plt.suptitle('Air Quality [Optimize: RMSprop]', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # suptitle과 그래프가 겹치지 않도록 조정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e43229-ac28-4dc4-852b-ffb1c5b2bede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# GRU 모델 정의\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# SimpleRNN(tanh) 모델 정의\n",
    "def build_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련\n",
    "lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "gru_model = build_gru_model((X_train.shape[1], X_train.shape[2]))\n",
    "rnn_model = build_rnn_model((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
    "gru_history = gru_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec1786-c722-4164-aeab-de5dc8e3f1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. 학습 및 검증 손실 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Epochs 기준 그래프\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(rnn_history.history['loss'], label='tanh train', color='blue')\n",
    "plt.plot(rnn_history.history['val_loss'], label='tanh valid', color='blue', linestyle='--')\n",
    "plt.plot(gru_history.history['loss'], label='GRU train', color='green')\n",
    "plt.plot(gru_history.history['val_loss'], label='GRU valid', color='green', linestyle='--')\n",
    "plt.plot(lstm_history.history['loss'], label='LSTM train', color='purple')\n",
    "plt.plot(lstm_history.history['val_loss'], label='LSTM valid', color='purple', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.title('Per epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 시간 기준 그래프\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(np.cumsum(rnn_history.history['loss']), label='tanh train', color='blue')\n",
    "plt.plot(np.cumsum(rnn_history.history['val_loss']), label='tanh valid', color='blue', linestyle='--')\n",
    "plt.plot(np.cumsum(gru_history.history['loss']), label='GRU train', color='green')\n",
    "plt.plot(np.cumsum(gru_history.history['val_loss']), label='GRU valid', color='green', linestyle='--')\n",
    "plt.plot(np.cumsum(lstm_history.history['loss']), label='LSTM train', color='purple')\n",
    "plt.plot(np.cumsum(lstm_history.history['val_loss']), label='LSTM valid', color='purple', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.title('Wall Clock Time (seconds)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cumulative Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 두 그래프를 합친 제목 추가\n",
    "plt.suptitle('Air Quality [Optimize: adam]', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # suptitle과 그래프가 겹치지 않도록 조정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3233aaf-dd52-4df6-86db-47ed10029410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "y_pred_gru = gru_model.predict(X_test)\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "\n",
    "# MSE 계산\n",
    "lstm_mse = mean_squared_error(y_test, y_pred_lstm)\n",
    "gru_mse = mean_squared_error(y_test, y_pred_gru)\n",
    "rnn_mse = mean_squared_error(y_test, y_pred_rnn)\n",
    "\n",
    "# MAE 계산\n",
    "lstm_mae = mean_absolute_error(y_test, y_pred_lstm)\n",
    "gru_mae = mean_absolute_error(y_test, y_pred_gru)\n",
    "rnn_mae = mean_absolute_error(y_test, y_pred_rnn)\n",
    "\n",
    "# R^2 Score 계산\n",
    "lstm_r2 = r2_score(y_test, y_pred_lstm)\n",
    "gru_r2 = r2_score(y_test, y_pred_gru)\n",
    "rnn_r2 = r2_score(y_test, y_pred_rnn)\n",
    "\n",
    "print(f\"LSTM MSE: {lstm_mse}, MAE: {lstm_mae}, R^2: {lstm_r2}\")\n",
    "print(f\"GRU MSE: {gru_mse}, MAE: {gru_mae}, R^2: {gru_r2}\")\n",
    "print(f\"RNN MSE: {rnn_mse}, MAE: {rnn_mae}, R^2: {rnn_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ba407-1975-47de-ae6d-6cdedb028dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
